{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "586cf995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "5f4ac614",
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv('train.csv')\n",
    "val=pd.read_csv('val_df.csv')\n",
    "\n",
    "#need to split the prediction variable out from the dataset\n",
    "X_train = train.drop('fail', axis=1)  # Features (input)\n",
    "y_train = train['fail']               # Target (label)\n",
    "\n",
    "X_val = val.drop('fail', axis=1)\n",
    "y_val = val['fail']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "995d16dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale the data, so the data is on the same scale. Mean=0, sd=1\n",
    "scaler=StandardScaler()\n",
    "scaler.fit(X_train) #fit only on training\n",
    "\n",
    "#transform both\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0d65f7",
   "metadata": {},
   "source": [
    "## Baseline using logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "3cb80a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score 0.8888888888888888\n",
      "acc 0.8829787234042553\n"
     ]
    }
   ],
   "source": [
    "baseline=LogisticRegression()\n",
    "#trained and predicts using the scaled versions\n",
    "baseline.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = baseline.predict(X_val_scaled)\n",
    "score = f1_score(y_val, y_pred)\n",
    "acc = accuracy_score(y_val, y_pred)\n",
    "print(f'score {score}')\n",
    "print(f'acc {acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "d764f6b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Feature  Importance\n",
      "5          VOC    2.420079\n",
      "3          USS    1.297031\n",
      "2           AQ    0.825277\n",
      "4           CS    0.603889\n",
      "0     footfall    0.266227\n",
      "6           RP    0.128148\n",
      "8  Temperature    0.105504\n",
      "7           IP    0.103049\n",
      "1     tempMode    0.092369\n"
     ]
    }
   ],
   "source": [
    "#logistic regressin futher\n",
    "\n",
    "#q coefficient of +3.0 is just as influential as -3.0\n",
    "coefs = np.abs(baseline.coef_[0])\n",
    "# Create DataFrame\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Importance': coefs\n",
    "})\n",
    "# Sort by strength\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "# Show top features\n",
    "print(feature_importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "3c57d938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean F1 score: 0.9038\n",
      "Mean Accuracy: 0.9219\n",
      "Validation Accuracy: 0.8830\n",
      "Validation F1 score: 0.8889\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    #scale the data\n",
    "    ('scaler', StandardScaler()),\n",
    "    #based on ANOVA, find the best variables against the fail.\n",
    "    ('selector', SelectKBest(score_func=f_classif, k=4)),\n",
    "    #tuning the logisticregression\n",
    "    ('logreg', LogisticRegression(penalty=\"l1\", C=1.0, max_iter=1000, solver='saga'))\n",
    "])\n",
    "\n",
    "# Define cross-validation strategy\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "# Evaluate using F1 score\n",
    "scores = cross_val_score(pipe, X_train, y_train, scoring='f1', cv=cv, n_jobs=-1)\n",
    "print(f\"Mean F1 score: {scores.mean():.4f}\")\n",
    "\n",
    "# Accuracy Score\n",
    "acc_scores = cross_val_score(pipe, X_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print(f\"Mean Accuracy: {acc_scores.mean():.4f}\")\n",
    "\n",
    "\n",
    "#Fit on full training set\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "#Predict on the hold-out validation set\n",
    "y_val_pred = pipe.predict(X_val)\n",
    "\n",
    "#Evaluate\n",
    "acc_val = accuracy_score(y_val, y_val_pred)\n",
    "f1_val = f1_score(y_val, y_val_pred)\n",
    "\n",
    "print(f\"Validation Accuracy: {acc_val:.4f}\")\n",
    "print(f\"Validation F1 score: {f1_val:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c57a48",
   "metadata": {},
   "source": [
    "## RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "26d094e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean F1 score: 0.8913\n",
      "Mean Accuracy: 0.9108\n",
      "Validation Accuracy: 0.8723\n",
      "Validation F1 score: 0.8776\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('selector', SelectKBest(score_func=f_classif, k=9)),\n",
    "    ('randomForest', RandomForestClassifier(random_state=42,n_estimators=100, min_samples_split=2, max_depth=5, ))\n",
    "])\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# Get best results\n",
    "scores = cross_val_score(pipe, X_train, y_train, scoring='f1', cv=cv, n_jobs=-1)\n",
    "acc_scores = cross_val_score(pipe, X_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\n",
    "print(f\"Mean F1 score: {scores.mean():.4f}\")\n",
    "print(f\"Mean Accuracy: {acc_scores.mean():.4f}\")\n",
    "\n",
    "#Fit on full training set\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "#Predict on the hold-out validation set\n",
    "y_val_pred = pipe.predict(X_val)\n",
    "\n",
    "#Evaluate\n",
    "acc_val = accuracy_score(y_val, y_val_pred)\n",
    "f1_val = f1_score(y_val, y_val_pred)\n",
    "\n",
    "print(f\"Validation Accuracy: {acc_val:.4f}\")\n",
    "print(f\"Validation F1 score: {f1_val:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
